# üîÑ Conversi√≥n Parquet a JSON para MongoDB

## RESPUESTA R√ÅPIDA: NO ES NECESARIO

El notebook **ya convierte autom√°ticamente** Parquet ‚Üí MongoDB usando PyMongo.

**Flujo actual:**
```
Parquet ‚Üí Pandas ‚Üí dict() ‚Üí MongoDB (BSON)
```

**NO necesitas** archivos JSON intermedios.

---

## M√©todos de Importaci√≥n a MongoDB

### M√âTODO 1: PyMongo (YA IMPLEMENTADO EN EL NOTEBOOK) ‚úÖ

**Ventajas:**
- ‚úÖ Conversi√≥n autom√°tica Parquet ‚Üí MongoDB
- ‚úÖ Control total sobre limpieza de datos
- ‚úÖ Inserci√≥n por lotes optimizada (20K documentos/batch)
- ‚úÖ Logging y manejo de errores
- ‚úÖ **No requiere archivos intermedios**

**C√≥digo (ya est√° en el notebook):**
```python
# Leer Parquet
df = pd.read_parquet('archivo.parquet')

# Limpiar
df_clean = clean_hvfhv_data(df)

# Convertir a diccionarios e insertar
records = df_clean.to_dict('records')
collection.insert_many(records, ordered=False)
```

---

### M√âTODO 2: mongoimport (Alternativa Manual)

Si prefieres usar la herramienta CLI de MongoDB:

**Paso 1: Convertir Parquet a JSON**

```python
import pandas as pd

# Leer Parquet
df = pd.read_parquet('fhvhv_tripdata_2025-01.parquet')

# Exportar a JSON (formato NDJSON para mongoimport)
df.to_json('output.json', orient='records', lines=True)
```

**Paso 2: Importar con mongoimport**

```powershell
mongoimport --uri "mongodb://localhost:27017/" `
            --db nyc_hvfhv_db `
            --collection trips `
            --file output.json `
            --jsonArray
```

**Desventajas:**
- ‚ùå Archivos JSON muy grandes (2-3x el tama√±o de Parquet)
- ‚ùå Sin limpieza de datos autom√°tica
- ‚ùå Proceso en 2 pasos (lento)
- ‚ùå Sin control de errores detallado

---

## M√âTODO RECOMENDADO: Usar el Notebook

**Razones:**

1. **Sin archivos intermedios** ‚Üí Ahorra espacio en disco
2. **Limpieza autom√°tica** ‚Üí Datos ya validados
3. **Logging detallado** ‚Üí Sabes qu√© pas√≥
4. **Batch insert** ‚Üí M√°s r√°pido que mongoimport
5. **√çndices autom√°ticos** ‚Üí Ya optimizado

---

## Comparaci√≥n de Rendimiento

| M√©todo | Tiempo (1M docs) | Espacio en Disco | Limpieza | √çndices |
|--------|------------------|------------------|----------|---------|
| **PyMongo (Notebook)** | ~5 min | Solo Parquet | ‚úÖ S√≠ | ‚úÖ Auto |
| mongoimport + JSON | ~15 min | Parquet + JSON (3x) | ‚ùå No | ‚ùå Manual |

---

## Si A√öN Quieres Exportar a JSON

**Script standalone:**

```python
# convert_parquet_to_json.py
import pandas as pd
from pathlib import Path

def convert_all_parquet_to_json():
    data_path = Path('./data')
    parquet_files = list(data_path.glob('*.parquet'))
    
    for parquet_file in parquet_files:
        print(f"üîÑ Convirtiendo {parquet_file.name}...")
        
        # Leer Parquet
        df = pd.read_parquet(parquet_file)
        
        # Convertir datetime a string
        for col in df.select_dtypes(include=['datetime64']).columns:
            df[col] = df[col].astype(str)
        
        # Exportar a JSON (NDJSON format)
        output_file = data_path / f"{parquet_file.stem}.json"
        df.to_json(output_file, orient='records', lines=True)
        
        print(f"‚úÖ Guardado: {output_file.name}")

if __name__ == "__main__":
    convert_all_parquet_to_json()
```

**Ejecutar:**
```powershell
python convert_parquet_to_json.py
```

---

## Conclusi√≥n

**USA EL NOTEBOOK** ‚Üí Es m√°s eficiente, r√°pido y profesional.

La conversi√≥n Parquet ‚Üí JSON ‚Üí MongoDB solo tiene sentido si:
- Quieres archivos JSON para otro prop√≥sito
- Est√°s usando una herramienta que solo acepta JSON
- Necesitas compartir los datos en formato JSON

Para este proyecto acad√©mico, **el notebook ya tiene todo optimizado**.
